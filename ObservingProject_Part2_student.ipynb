{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>OBSERVATIONAL ASTROPHYSICS – FALL 2019 OBSERVING EXERCISE- Part 2</h2>\n",
    "<h4></h4>\n",
    "<i>Note: Enter in all code to the problems in the provided notebook cells. Questions to answer will be <b>bolded</b>.  However, you need to read <b>all the text carefully</b> as you will otherwise miss important elements.</i> \n",
    "\n",
    "This assignment is due on Sunday night at 11:59pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: astropy.extern.six will be removed in 4.0, use the six module directly if it is still needed [astropy.extern.six]\n"
     ]
    }
   ],
   "source": [
    "#***Run this block but DO NOT CHANGE***\n",
    "\n",
    "#Nothing to do here. Just some things defined for use later. \n",
    "from astroplan.plots import plot_finder_image\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.skyview import SkyView\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg' #This is here to make the plots appear high-resolution\n",
    "\n",
    "def get_RA_deg(RA_HMS):\n",
    "    #Convert RA from HMS to decimal degrees\n",
    "    H, M, S = [float(i) for i in RA_HMS.split()]\n",
    "    rs = 1\n",
    "    if str(H)[0] == '-': \n",
    "      rs, H = -1, abs(H)\n",
    "    deg = (H*15) + (M/4) + (S/240)\n",
    "    RA = '{0}'.format(deg*rs)\n",
    "    return float(RA)\n",
    "    \n",
    "def get_DEC_deg(DEC_DMS):\n",
    "    #Convert DEC from DMS to decimal degrees\n",
    "    ds = 1\n",
    "    D, M, S = [float(i) for i in DEC_DMS.split()]\n",
    "    if str(D)[0] == '-':\n",
    "      ds, D = -1, abs(D)\n",
    "    deg = D + (M/60) + (S/3600)\n",
    "    DEC = '{0}'.format(deg*ds)\n",
    "    return float(DEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Given your window of opportunity, first identify all open clusters that meet your time criteria from Part 1 (there will be lots of options since we are merely selecting an area of the sky as out first cut).\n",
    "    \n",
    "You will be using the “WEBDA” database at https://webda.physics.muni.cz/ .  This is an online database of stellar clusters that is a compiled version of clusters and lots of the data that is available for them.  \n",
    "\n",
    "<b>1) Read the \"Description\" page at https://webda.physics.muni.cz/description.html </b>\n",
    "\n",
    "You can access data in the following way.  From the main page go to the following link: Navigation→Available Data and Parameters.   This brings you a query tool that you can use to request clusters in a range of coordinates, with a minimum number of stars, and with a certain type of available data.  The Available Data and Parameters link is in the top right of the Navigation page under “Interrogation.”\n",
    "\n",
    "To start with query the clusters using the following criteria:\n",
    "<ol>\n",
    "    <li>The range of RA and DEC that you determined in PART 1 for your observing block</li>\n",
    "<li>A minimum number of stars that you will need to get a proper color-magnitude diagram.  Start with 100 and based on your work below, change this value to a higher or lower value depending on what you think you need to get a good CMD.</li>\n",
    "<li>For the dropdown menu by “datatype” choose “UBV CCD observations”.  That will only choose clusters that have existing observations that we can use to calibrate our data.</li>\n",
    "</ol>\n",
    "This query will result in many clusters.  You will need to pick your targets using the following criteria.  This will involve clicking through the clusters individually to find a good one.  My suggestion is to build up a sample of clusters using the main query and then keeping a table, perhaps on a google sheet or excel sheet.  Then you can keep track of the answers to the different questions below so that you can pare down your list. </p>  \n",
    "\n",
    "<b><i>You should upload your final table or spreadsheet to GitHub as part of this assigment.  The version of the table/spreadsheet that you upload to GitHub doesn't need to contain every cluster you looked at.  It just needs to give the ~6 objects that you have at the end of #3 below and comments for each cluster about each of the remaining questions.  It must contain a clear indication of which clusters comprise your final sample.  It should also have any important notes about each cluster that led you to choose it.</b></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2)   How big in angular size is the cluster?</b> \n",
    "<p>\n",
    "If the cluster is too large, you may not be able to observe most of it within the FOV of the camera, meaning that you won’t be able to get your observations completed without doing multiple, overlapping fields.  You can determine this a variety of ways.  If there is an image of the cluster on the main page, with a size scale, you can compare this to the FOV of the instrument that you computed in Part 1.  You can also use the <u>“From cluster chart (plotted)”</u> link under Query.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3)   How sparsely (densely) populated is the cluster field?</b>\n",
    "<p>If the cluster is composed of a handful of stars against a rich background field, the dominant majority of what you observe may not be in the cluster and identifying the cluster members may be an exercise in self-delusion. If the cluster is exceptionally rich/crowded, you may have a challenging time getting good photometry because the stellar images overlap. This is a common problem with globular clusters, which contain hundreds of thousands of stars, but it can also affect open clusters if they are too distant, thereby squeezing a large sample of stars into a small angular diameter.   Again, you can get this through either the image or the finder chart.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************************************\n",
    "<p>At this point, you want to have an observing list of ~6 potential clusters. For the next set of constraints, <i>you need to determine how much we already know about each cluster on your list from already available observations.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>4)  Does the cluster have published right ascensions and declinations of the stars?</b>\n",
    "<p>This will be important for when we want to use other observations to calibrate our data (see below.)  Under the main page for each cluster, you can use the “Available Data” link under the WEBDA content heading.  For the cluster to have coordinates there needs to be a  “Coordinates J2000” link and there needs to be a large list of stars with existing coordinates.  Not every cluster has RA and DEC coordinates as some people only published positions of stars on their CCD.  So you need to double check this.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5)   Does CCD photometry already exist that would give you some insight into the expected color-magnitude diagram (CMD) for the cluster, once your photometry is completed? </b>\n",
    "\n",
    "This should be true as we did the query on a subset of clusters with UBV CCD photometry.  However, it is good to make sure of that, and to be sure that there are many stars with photometry. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>6)   If a CMD exists for the cluster, does it look like a scatter plot or is there a respectable locus of points that probably includes the cluster members? </b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>7)   How bright are the brightest apparent stars in the cluster? </b> \n",
    "<p>Brighter stars require shorter exposures but, if stars are too bright, they will quickly saturate the CCD chip in the region of the star and possibly affect fainter stars nearby. Note that this answer is sometimes coupled to the answer to (i) since nearby clusters have stars with bright apparent magnitudes (= small distance modulus). </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>8)   How faint are the faintest stars you wish to observe?</b>\n",
    "\n",
    "<p>This requires a bit more work because you want to look at the color-magnitude diagram of the cluster to get some sense of how faint you need to observe to get a decent chunk of the CMD.  Assume that in a given band you don’t want to have to expose for longer than 15 minutes in total and that you want to get photometry in the B and V  bands.  You also want a signal-to-noise (SNR) of at least 15 for your faintest stars.  To calculate the faintest star that you can observe in 15 minutes at an SNR=15 you need to do a computation.  \n",
    "\n",
    "For our detector and telescope a star of 20th magnitude in B and V gets 1815 and 1944 photons respectively in a 100s exposure.  The star’s light is spread over 10 pixels.  Let us conservatively (because the brightness is high then) assume that we are observing 1 day from full moon.  In that case the background per pixel is 396.3 and 295.5 in the B and V band respectively in a 100 sec. exposure.  Describe in a text cell below your computational cell whether or not you can neglect the read noise and why?  From these numbers you can calculate the the faintest magnitude that yields you a SNR=20 in 15 minutes.\n",
    "\n",
    "<b>Your code should print out the following, with explanatory text:\n",
    "    <li>a) total number of background counts in B and V in 15min for the summed pixels in an object aperture;\n",
    "    <li>b) the noise from the background in 15min for the summed pixels in an object aperture;\n",
    "    <li>c) the number of counts in 15min for B and V that correspond to the desired SNR;\n",
    "    <li>d) the number of counts in B and V for a 20th magnitude star in 15min;\n",
    "    <li>e) the magnitude in B and V corresponding to the limiting number of counts in c).\n",
    "</b>\n",
    "\n",
    "For this calculation, assume the gain is 1.  This means that if I get one photon, my CCD counts 1 electron.  Since Poisson noise is computed on the incident photons and not the number of measured electrons, you need to convert your counts to photons.  We will assume for now that this is a 1-to-1 conversion (Gain=1).  This is not correct but will be ok for this calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) The number of BKG counts in B and V in 15min is:  35667.0 26595.0\n",
      "b) BKG noise in B and V:  188.8570888264457 163.0797350991226\n",
      "c) limiting counts for SNR limit in B and V:  2832.8563323966855 2446.196026486839\n",
      "d) the number of counts in B and V for a 20th mag object in 15min:  16335.0 17496.0\n",
      "e) magnitude limits in B and V corresponding to our SNR limit:  18.56628379010858 18.332401478167125\n"
     ]
    }
   ],
   "source": [
    "#Answer 8) Here\n",
    "#YOUR CODE GOES HERE\n",
    "\n",
    "BKG15_B=15*60/100*396.3*10\n",
    "BKG15_V=15*60/100*295.5*10  #minutes * sec/min * counts/s/pix *pix = total counts\n",
    "\n",
    "\n",
    "real_counts_B=181.5*9*10\n",
    "real_counts_V=194.4*9*10 #9 comes from (60*15=900   /100) = 9 *counts/10pix*10pix == counts in 15 minutes\n",
    "SNR=15\n",
    "\n",
    "noise_B=(BKG15_B)**0.5\n",
    "noise_V=(BKG15_V)**0.5\n",
    "counts_b=SNR*noise_B\n",
    "counts_v=SNR*noise_V\n",
    "#Hint: You need to use the information about the number of counts \n",
    "#for different sources that I give above.\n",
    " \n",
    "#let us define the flux of m=20 \n",
    "\n",
    "F_20=10**(20/-2.5)   #== 1e-8\n",
    "BKG20_B=12*3963\n",
    "BKG20_V=12*2955\n",
    "counts_b_20=20*(BKG20_B)**.5\n",
    "counts_v_20=20*(BKG20_V)**.5\n",
    "f_B=F_20*real_counts_B/counts_b_20\n",
    "f_V=F_20*real_counts_V/counts_v_20\n",
    "\n",
    "##m1-m2 = -2.5 log(F_20/f_B)\n",
    "\n",
    "m_B_limit=((-2.5*np.log10(F_20/f_B))-20)*-1\n",
    "m_V_limit=((-2.5*np.log10(F_20/f_V))-20)*-1\n",
    "\n",
    "#In each band, think about the noise from the background over the \n",
    "#whole size of the source when observed in 15min.  From this and the \n",
    "#SNR requirement you can determine the number of object counts that you need \n",
    "#to have the required SNR (see lecture notes).  Finally, the flux from a \n",
    "#20th mag object can then be used to convert that number of counts to a \n",
    "#limiting magnitude.\n",
    "\n",
    "#first measure the total background expected in 15 minutes\n",
    "\n",
    "print(\"a) The number of BKG counts in B and V in 15min is: \", BKG15_B , BKG15_V )\n",
    "\n",
    "\n",
    "print(\"b) BKG noise in B and V: \", noise_B, noise_V )\n",
    "\n",
    "#now determine the number of object counts needed in 15 minutes to get the desired SNR.  \n",
    "print(\"c) limiting counts for SNR limit in B and V: \", counts_b, counts_v  )\n",
    "\n",
    "print(\"d) the number of counts in B and V for a 20th mag object in 15min: \", real_counts_B, real_counts_V  )\n",
    "\n",
    "print(\"e) magnitude limits in B and V corresponding to our SNR limit: \", m_B_limit, m_V_limit )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###!!!!!!!!!!!!!!!!!!I ran out of time!!!!!!!!! I had a busy weekend as was not able to complete the assignment. \n",
    "#My answer to 8 E is not correct but I will likely not have time to complete this tonight sorry :(#\n",
    "#here is a link to my target spreadsheet I also was not able to get around to answering 7#\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now decide whether your clusters have enough stars above this limit to be able to construct an adequate CMD.\n",
    "\n",
    "<i>Note that you you don’t need to go as faint as possible.  You need to make a decision based on the characteristics of the cluster CMD.  For example, at the calculated magnitude limit are you just picking up the cluster giant branch or are you getting some fraction of the turnoff and main sequence?   You want a cluster such that your magnitude limit allows you to go deep enough to learn something about the cluster.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 9)   How good are the available cluster data?</b>\n",
    "<p>If the cluster has been studied many times and there is lots of published data, give a reason why you might be observing it again? If there is little to no published data, why has everybody ignored it? Keep in mind that you’d like to have some means of calibrating the photometry. If there are no existing observations in the cluster and the skies are usable but not photometric, e.g. there is light cirrus that varies hourly, you won’t be able to calibrate your CCD frames using external (outside the cluster) standards, so some internal means of checking your photometry would be crucial. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "<i> By this point you should have enough information to pick 2-3 clusters that you might want to observe given all of the conditions above.  Below you will make some plots for each of these clusters.  </i>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> We will now provide you with a way to make CMDs and a histogram of the V-band magnitudes. To do this, you will need to click the \"Available Data\" link on the wbeda interface, and then click the \"UBV CCD\" link. This should bring you to a table of values with 5 columns: No, Ref, V, B-V, and U-B. <b>Copy and paste this entire table (inlcuding the columns names) into a text editor of your choice, and save it as a text file. You can then use the make_plots() function (defined below), by passing in as input the string of your file name (ex: \"cluster.txt\").</b> Please note that you need to use the cell block below the block of code directly below this text cell where the function is defined (if you try to call make_plots() before the cell it is written in you will get an error). You also need to make sure that the file with the data (there will be different ones for each cluster) is in the same directory as where the notebook is.  This isn't a generic requirement of such codes, but what we are doing here.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***RUN THIS BLOCK. If you wish to change the font sizes in the plots, you can do so here.  ***\n",
    "\n",
    "#Now we just define some settings for our plots. \n",
    "params = {\n",
    "    'text.latex.preamble': ['\\\\usepackage{gensymb}'],\n",
    "    'image.origin': 'lower',\n",
    "    'image.interpolation': 'nearest',\n",
    "    'image.cmap': 'gray', #gray\n",
    "    'axes.grid': False,\n",
    "    'savefig.dpi': 300,  \n",
    "    'axes.labelsize': 14, # fontsize for x and y labels\n",
    "    'axes.titlesize': 20, \n",
    "    'font.size': 14, \n",
    "    'legend.fontsize': 10, \n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12, \n",
    "    'text.usetex': False,\n",
    "    'figure.figsize': [6, 6], #[width, height]\n",
    "    'figure.autolayout': False,\n",
    "    'font.family': 'monospace',\n",
    "}\n",
    "matplotlib.rcParams.update(params) #activate the settings\n",
    "\n",
    "def make_plots(file_name):\n",
    "    print(\"********************************************\")\n",
    "    print(\"Plots for file: \"+file_name)\n",
    "    print(\"********************************************\")\n",
    "    #We load in the first 4 columns of the file\n",
    "    data = np.loadtxt(file_name,skiprows = 0,usecols = (0,1,2,3), dtype={'names': ('No', 'Ref', 'V', 'B-V'), 'formats': ('S8', 'S16', 'S16','S16')})\n",
    "    \n",
    "    #We need to handle duplicates in the file, so we find indeces of unique sources\n",
    "    indeces_use = []\n",
    "    len_data = len(data)\n",
    "    for i in range(1,len_data-1): #Skip first row since it contains columns names.\n",
    "        if data[i][0] != data[i+1][0]: #Check if the next source is a repeat\n",
    "            indeces_use.append(i) #If it is not a repeat, it is unique and we record its index.\n",
    "            \n",
    "    num_sources = len(indeces_use) #Number of actual unique sources\n",
    "    \n",
    "    #We will now average over the magnitudes for repeated sources\n",
    "    V_avg = np.zeros(num_sources)\n",
    "    BV_avg = np.zeros(num_sources)\n",
    "    for i in range(num_sources):\n",
    "        current_index = indeces_use[i] #Keep track of the first index that this source appears at\n",
    "        num_i = 1 #Keep track of the number of sources with this source name\n",
    "        V_tot = float(data[current_index][2])\n",
    "        BV_tot = float(data[current_index][3])\n",
    "        #While the next source has the same source name\n",
    "        while current_index < (num_sources - 2) and data[current_index][0] == data[current_index+1][0]:\n",
    "            current_index += 1 #We go to the next repeat of this source.\n",
    "            num_i += 1 \n",
    "            V_tot += float(data[current_index][2]) #Add the next value forn this repeated source to the total mag\n",
    "            BV_tot += float(data[current_index][3])\n",
    "        V_avg[i] = V_tot/num_i\n",
    "        BV_avg[i] = BV_tot/num_i\n",
    "\n",
    "    #Make the figure for the CMD\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel(r'$B-V\\ [mag]$')\n",
    "    ax1.set_ylabel(r'$V\\ [mag]$')\n",
    "    ax1.grid(which= 'major', linestyle='-', linewidth='0.5', color = 'black', alpha = 0.3)\n",
    "    ax1.grid(which='minor', linestyle=':', linewidth='0.3', color = 'black', alpha = 0.2)\n",
    "    ax1.scatter(BV_avg, V_avg, marker = '.', c='k')\n",
    "\n",
    "    #Create good min and max values for CMD axes, and set axis limits. \n",
    "    x_min_plot = np.min(BV_avg)-abs(.1*np.min(BV_avg))\n",
    "    x_max_plot = 1.1*np.max(BV_avg)\n",
    "    y_min_plot = np.min(V_avg)-abs(.1*np.min(V_avg))\n",
    "    y_max_plot = 1.1*np.max(V_avg)\n",
    "    ax1.set_xlim([float(x_min_plot), float(x_max_plot)])\n",
    "    ax1.set_ylim([float(y_max_plot), float(y_min_plot)])\n",
    "    ax1.set_title(r'Color Magnitude Diagram')\n",
    "\n",
    "    #Make figure for histogram. \n",
    "    fig2, ax2 = plt.subplots()\n",
    "    ax2.hist(V_avg, bins = 'auto',histtype ='step', color = 'k', lw = 1.5)\n",
    "    ymin_hist, ymax_hist = ax2.get_ylim()\n",
    "    xmin_hist, xmax_hist = ax2.get_xlim()\n",
    "    #Write on the number of total sources for reference\n",
    "    ax2.annotate( 'N = '+str(num_sources), xy = ( xmin_hist + 0.05*(xmax_hist-xmin_hist), ymax_hist - 0.1*ymax_hist))\n",
    "    ax2.set_title(r'V mag Histogram')\n",
    "    ax2.set_xlabel(r'$V\\ [mag]$')\n",
    "    ax2.set_ylabel(r'Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************\n",
      "Plots for file: cluster.txt\n",
      "********************************************\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cluster.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b1a17e9b7013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmake_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cluster.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-f6f062c46a53>\u001b[0m in \u001b[0;36mmake_plots\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"********************************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#We load in the first 4 columns of the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskiprows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0musecols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'No'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Ref'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'V'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'B-V'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'formats'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'S8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'S16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'S16'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'S16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#We need to handle duplicates in the file, so we find indeces of unique sources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3env/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3env/lib/python3.7/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python3env/lib/python3.7/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    622\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cluster.txt not found."
     ]
    }
   ],
   "source": [
    "#*****************\n",
    "#In this block of code you will make a CMD plot and a V-band magnitude histogram.\n",
    "#You will need to repeat this for each cluster.\n",
    "\n",
    "#Example call of make_plots for the file \"cluster.txt\"\n",
    "#   \n",
    "#    make_plots(\"cluster.txt\")\n",
    "#\n",
    "#Replace \"cluster.txt\" with the name of your files. You will need to do this for all clusters you use, using a \n",
    "#separate text file and call of make_plots for each cluster. \n",
    "#YOUR CODE HERE\n",
    "\n",
    "make_plots(\"cluster.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For each cluster, comment on the characteristics of the two graphs</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***RUN THIS BLOCK***\n",
    "#This is a routine to pull images from the web at the location of your source and \n",
    "#to overlay the MLO 40-inch Camera's field of view\n",
    "\n",
    "def make_finder(RA_HMS, DEC_DMS, fov, img_width=20/60, img_height=20/60):\n",
    "    #Use the RA and DEC to make a SkyCoord object, which we use to query and image\n",
    "    RA_DEG = get_RA_deg(RA_HMS) #convert to Degrees\n",
    "    DEC_DEG = get_DEC_deg(DEC_DMS)\n",
    "    source_coord = SkyCoord(ra= RA_DEG*u.deg,dec = DEC_DEG*u.deg)\n",
    "\n",
    "    #Query an image using astroquery with the given coordinates and image width/height\n",
    "    xout = SkyView.get_images(source_coord,survey=['DSS'],height=img_height*u.deg,width=img_width*u.deg)\n",
    "    \n",
    "    #Make the figure object and handle the fits image appropriately.\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    b=xout[0][0]\n",
    "    ax.imshow(xout[0][0].data,aspect='equal',cmap='gray_r',extent=[b.header['CRVAL1']-(b.header['NAXIS1']-b.header['CRPIX1'])*b.header['CDELT1'],\n",
    "                                                               b.header['CRVAL1']+(b.header['NAXIS1']-b.header['CRPIX1'])*b.header['CDELT1'],\n",
    "                                                               b.header['CRVAL2']+(b.header['NAXIS2']-b.header['CRPIX2'])*b.header['CDELT2'],\n",
    "                                                               b.header['CRVAL2']-(b.header['NAXIS2']-b.header['CRPIX2'])*b.header['CDELT2']])\n",
    "    #Overlay a rectangle indicating the fov\n",
    "    rect = plt.Rectangle((RA_DEG-0.5*(fov),DEC_DEG-0.5*(fov)) ,fov,fov,linewidth=1,fill=False, color='k')\n",
    "    plt.gca().add_artist(rect)\n",
    "    ax.set_xlabel(r'RA [DEG]')\n",
    "    ax.set_ylabel(r'DEC [DEG]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************\n",
    "#This block of code allows you to make a finder chart for your cluster using the make_finder() function \n",
    "#defined above.\n",
    "#You will need to do this for each of your three clusters.  \n",
    "#We provide example code below.\n",
    "\n",
    "####First, define the RA and DEC of the cluster as follows, in HMS for RA and DMS for DEC\n",
    "#source_RA = '07 38 46'\n",
    "#source_DEC = '-33 50 36'\n",
    "#\n",
    "####Now, define the fov in arcmin. This should be the fov of your instrument from part 1\n",
    "#fov = 12.7\n",
    "#fov_degrees = fov/60\n",
    "#\n",
    "#make_finder(source_RA, source_DEC, fov_degrees)\n",
    "#***********YOUR CODE HERE\n",
    "\n",
    "source_RA = ''\n",
    "source_DEC = ''\n",
    "fov =   #in arcmin\n",
    "fov_degrees = fov/60\n",
    "make_finder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><p>\n",
    "Your completed version of the Jupyter Notebook template will need to have for each cluster:\n",
    "<ol>  \n",
    "    <li>A plot of the RA and DEC of the cluster with an outline of the field of view of the detector centered on the cluster.</li>\n",
    "    <li>A histogram of the V-band magnitudes of the cluster members</li>\n",
    "    <li>A color-magnitude diagram of the B-V vs V-band for all the stars in the cluster field.  </li>\n",
    "</ol>\n",
    "\n",
    "You will also need to have a block of summary text that describes your choice of clusters.\n",
    "</p></b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
